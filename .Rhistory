getwd
getwd()
install.packages("knitr")
install.packages("servr")
library(servr)
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
library(SparkR)
sc <- sparkR.init(master = "local", appName = "MyApp")
sqlCtx <- SparkRSQL.init(sc)
sqlCtx <- sparkRSQL.init(sc)
remove.packages(SparkR)
remove.packages("SparkR")
library(SparkR)
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
# Next, we download packages that H2O depends on.
if (! ("methods" %in% rownames(installed.packages()))) { install.packages("methods") }
if (! ("statmod" %in% rownames(installed.packages()))) { install.packages("statmod") }
if (! ("stats" %in% rownames(installed.packages()))) { install.packages("stats") }
if (! ("graphics" %in% rownames(installed.packages()))) { install.packages("graphics") }
if (! ("RCurl" %in% rownames(installed.packages()))) { install.packages("RCurl") }
if (! ("rjson" %in% rownames(installed.packages()))) { install.packages("rjson") }
if (! ("tools" %in% rownames(installed.packages()))) { install.packages("tools") }
if (! ("utils" %in% rownames(installed.packages()))) { install.packages("utils") }
# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/rel-shannon/19/R")))
library(h2o)
localH2O = h2o.init()
# Finally, let's run a demo to see H2O at work.
demo(h2o.kmeans)
h2o.shutdown()
getwd()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jekyll()
servr::jejekyll()
servr::jekyll()
Sys.setenv(SPARK_HOME = "C:/Apache/spark-1.4.1")
.libPaths(c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib"), .libPaths()))
#load the Sparkr library
library(SparkR)
# Create a spark context and a SQL context
sc <- sparkR.init(master = "local")
sqlContext <- sparkRSQL.init(sc)
DF <- createDataFrame(sqlContext, faithful)
head(DF)
localDF <- data.frame(name=c("John", "Smith", "Sarah"), age=c(19, 23, 18))
# Convert local data frame to a SparkR DataFrame
df <- createDataFrame(sqlContext, localDF)
# Print its schema
printSchema(df)
path <- file.path(Sys.getenv("SPARK_HOME"), "examples/src/main/resources/people.json")
peopleDF <- jsonFile(sqlContext, path)
printSchema(peopleDF)
# Register this DataFrame as a table.
registerTempTable(peopleDF, "people")
# SQL statements can be run by using the sql methods provided by sqlContext
teenagers <- sql(sqlContext, "SELECT name FROM people WHERE age >= 13 AND age <= 19")
# Call collect to get a local data.frame
teenagersLocalDF <- collect(teenagers)
# Print the teenagers in our dataset
print(teenagersLocalDF)
# Stop the SparkContext now
sparkR.stop()
# Create a spark context and a SQL context
sc <- sparkR.init(master = "local")
sqlContext <- sparkRSQL.init(sc)
servr::jekyll()
